%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Stylish Article
% LaTeX Template
% Version 2.1 (1/10/15)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Mathias Legrand (legrand.mathias@gmail.com) 
% With extensive modifications by:
% Vel (vel@latextemplates.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[fleqn,10pt]{SelfArx} % Document font size and equations flushed left
\usepackage[english]{babel} % Specify a different language here - english by default
\usepackage{lipsum} % Required to insert dummy text. To be removed otherwise
\usepackage{url} % Required to insert dummy text. To be removed otherwise

\usepackage{balance}

\usepackage{hyperref}
\usepackage{mathptmx}
\usepackage{times}
\usepackage{textcomp}
\usepackage{gensymb} % degree. ie 360º
\usepackage{amsmath}
\usepackage{comment}

\usepackage{graphicx,url,subfigure}
\usepackage{multirow}
\usepackage{subfigure}
\usepackage{graphicx}
\usepackage{booktabs}



\usepackage{tcolorbox}% http://ctan.org/pkg/tcolorbox
\definecolor{mycolor}{rgb}{0,0,0}% Rule colour
\makeatletter
\newcommand{\mybox}[1]{%
	\setbox0=\hbox{#1}%
	\setlength{\@tempdima}{\dimexpr\wd0+13pt}%
	\begin{tcolorbox}[colframe=mycolor,boxrule=0.5pt,arc=4pt,
		left=6pt,right=6pt,top=6pt,bottom=6pt,boxsep=0pt,width=\@tempdima]
		#1
	\end{tcolorbox}
}
\makeatother


\usepackage[resetlabels,labeled]{multibib}
\newcites{A}{Appendix}

\usepackage[num]{abntex2cite}
\citebrackets[]

%----------------------------------------------------------------------------------------
%	COLUMNS
%----------------------------------------------------------------------------------------

\setlength{\columnsep}{0.55cm} % Distance between the two columns of text
\setlength{\fboxrule}{0.75pt} % Width of the border around the abstract

%----------------------------------------------------------------------------------------
%	COLORS
%----------------------------------------------------------------------------------------

\definecolor{color1}{RGB}{0,0,90} % Color of the article title and sections
\definecolor{color2}{RGB}{0,20,20} % Color of the boxes behind the abstract and headings

%----------------------------------------------------------------------------------------
%	HYPERLINKS
%----------------------------------------------------------------------------------------

\usepackage{hyperref} % Required for hyperlinks
\hypersetup{hidelinks,colorlinks,breaklinks=true,urlcolor=color2,citecolor=color1,linkcolor=color1,bookmarksopen=false,pdftitle={Title},pdfauthor={Author}}

%----------------------------------------------------------------------------------------http://www.ecomp.poli.br/~wcci2018/registration/
%	ARTICLE INFORMATION
%----------------------------------------------------------------------------------------

\JournalInfo{\color{gray}\normalsize\sffamily\bfseries Revista de Informática Teórica e Aplicada - RITA - ISSN 2175-2745\\ Vol.~25, Num.~1~(2018)~82-89} % Journal information
\Archive{\mybox{RESEARCH ARTICLE}} % Additional notes (e.g. copyright, DOI, review/research article)




\PaperTitle{Glaucoma Diagnosis Using Texture attributes and Pre-trained CNN's} % Article title

\ShortTitle{Glaucoma Diagnosis Using Texture attributes and Pre-trained CNN's} % Article 

\Titulo{Diagnóstico de Glaucoma Utilizando Atributos de Textura e CNN's Pré-treinadas}



\PaperVol{25} % Volume 

\PaperNum{1} % Number 

\PaperAno{2018} % Number 


\Authors{Maíla de Lima Claro\textsuperscript{1}*, Rodrigo de Melo Souza Veras\textsuperscript{1}, André Macedo Santana\textsuperscript{1}, Luis Henrique Silva Vogado\textsuperscript{1} and Leonardo Pereira de Sousa\textsuperscript{2}} % Authors
\affiliation{\textsuperscript{1}\textit{Departamento de Computação, Federal University of Piauí, Brazil}} % Author affiliation
\affiliation{\textsuperscript{2}\textit{Curso de Sistemas de Informação, Federal University of Piauí, Brazil}} % Author affiliation
\affiliation{*\textbf{Corresponding author}: claromaila@gmail.com} % Corresponding author

\Keywords{medical images --- glaucoma diagnosis --- texture features --- transfer learning} % Keywords - if you don't want any simply remove all the text between the curly brackets



\newcommand{\keywordname}{Keywords} % Defines the keywords heading name

\PalavrasChave{imagens médicas --- diagnóstico de glaucoma --- atributos de textura --- transferência de aprendizagem} % Keywords - if you don't want any simply remove all the text between the curly brackets



\Doi{http://dx.doi.org/10.22456/2175-2745.76387}
\DateR{19/07/2017} % Received
\DateA{12/02/2018} % Accepted

%----------------------------------------------------------------------------------------
%	ABSTRACT
%----------------------------------------------------------------------------------------

\Abstract{Glaucoma is a disease that damages the optic nerve. It is considered the second leading cause of blindness in the world. Several automatic diagnostic systems have been proposed. However, such systems have not been shown to be able to handle a great diversity of images. Thus, this work proposes a method of detecting glaucoma, through the use of texture descriptors and Convolutional Neural Networks (CNNs). Tests were conducted in four public databases, making a total of 873 images. The results showed that the junction of GLCM and pre-trained CNN descriptors and the use of the Random Forest classifier are promising in the detection of this pathology, obtaining an accuracy of 91.06\%.}

\Resumo{Glaucoma é uma doença que danifica o nervo óptico. Ela é considerada  a segunda principal causa de cegueira no mundo. Vários sistemas de diagnóstico automático têm sido propostos, contudo, tais sistemas não demonstraram ser capazes de lidar com uma grande diversidade de imagens. Dessa forma,  este trabalho propõe um método de detecção do glaucoma, através do uso de descritores de textura e Redes Neurais Convolucionais (CNNs). Testes foram conduzidos em quatro bases públicas, o que constitui um total de 873 imagens. Os resultados mostraram que a junção dos descritores GLCM e CNNs pré-treinadas e a utilização do classificador  Random Forest são promissores na detecção dessa patologia, obtendo uma acurácia de 91,06\%..}

%----------------------------------------------------------------------------------------

\begin{document}
	
	\setcounter{page}{82}
	
	\flushbottom % Makes all text pages the same height
	\maketitle % Print the title and abstract box
	\thispagestyle{empty} % Removes page numbering from the first page
	%\tableofcontents % Print the contents section
	
	
	





\section{Introdução}
Diversas pesquisas com utilização de abordagens computacionais têm se encaminhado para auxiliar o diagnóstico de doenças. Esses estudos objetivam apoiar o médico especialista na identificação de patologias, podendo prevenir sua evolução, desde que diagnosticada precocemente.

No campo oftalmológico, foram desenvolvidos um grande número de sistemas de Diagnóstico Auxiliado por Computador (CAD - \textit{Computer Aided Diagnosis}) para o auxílio na detecção de vários tipos de doenças oculares, entre elas o glaucoma \cite{usman2016computer}. Estes sistemas têm potencial para fornecer uma solução alternativa aos programas de triagem em massa, que precisam examinar um grande número de imagens de fundo de olho de forma eficiente e robusta.

Nos estágios iniciais o glaucoma tende a ser assintomático. A descoberta precoce desta patologia é imprescindível, pois existem tratamentos que evitam a sua progressão e, consequentemente, a perda da visão do paciente. De acordo com a Organização Mundial de Saúde, existem cerca de 60 milhões de glaucomatosos em todo o mundo, sendo que, a cada ano, surgem mais 2,4 milhões de casos. Uma estimativa sugere que, em 2020, cerca de 80 milhões de pessoas terão essa doença \cite{Quigley:2006}.

O diagnóstico de glaucoma pode ser gerado a partir da análise de imagens digitais de retina. O mesmo só é possível devido a quantidade de perda de fibras do nervo óptico ter um efeito direto na configuração da rima neural. À medida que as fibras ópticas nervosas vão morrendo, a escavação (\textit{cup}) torna-se mais larga em relação ao disco óptico (DO), o que acarreta em um valor da relação Escavação/Disco (\textit{Cup to Disc Ratio} - CDR) aumentado \cite{Mittapalli:2016}, como pode ser visto na Figura \ref{fig:ExemplosImgs}. A região do DO (representada por toda a área dentro da marcação branca), e a região da escavação (toda a área dentro da marcação verde) estão em evidência. A Figura \ref{fig:Normal1} apresenta uma imagem de retina saudável, enquanto que a Figura \ref{fig:Glaucoma1} apresenta uma imagem com glaucoma.



\begin{figure*}[h!]
	\centering
	\subfigure{
		\label{fig:Normal1}
		\includegraphics[width=\columnwidth]{Figs/Marcada_Normal1}}
	\subfigure{
		\label{fig:Glaucoma1}
		\includegraphics[width=\columnwidth]{Figs/Marcada_Glaucoma1}}
	\caption{Exemplos de imagens da base RIM-ONE-3 com DO (marcação branca) e \textit{cup} (marcação verde) em evidência: (a) Imagem de uma retina saudável e (b) Imagem de uma retina glaucomatosa.}
	\label{fig:ExemplosImgs}
\end{figure*}


Existem vários algoritmos na literatura para o processamento e análise de imagens da retina visando o diagnóstico automático do glaucoma. Contudo, diferentes grupos de pesquisadores tendem a utilizar abordagens diferenciadas para que estes obtenham um melhor desempenho. O objetivo deste artigo é realizar a detecção automática do glaucoma em imagens da retina. Com o objetivo de desenvolver o nosso método foi realizado diversos experimentos que utilizam descritores de textura, forma e redes neurais convolucionais (\textit{Convolutional Neural Networks} - CNNs) como atributos de entrada para os classificadores \textit{Random Forest} (RF), \textit{Support Vector Machine} (SVM) e \textit{MultiLayer Perceptron} (MLP).

O presente trabalho tem a seguinte organização: Seção \ref{TR} apresenta os trabalhos relacionados referentes à identificação do glaucoma; Seção \ref{MM} descreve as bases de imagens utilizadas, os descritores utilizados neste trabalho e a apresentação da seleção de atributos e dos classificadores utilizados na detecção do glaucoma e as métricas de avaliação; Seção \ref{RD} demonstra os resultados obtidos e a Seção \ref{DIS} discute estes resultados e por fim, a Seção \ref{CO} expõe a conclusão deste trabalho.


\section{Trabalhos Relacionados}
\label{TR}

Realizou-se uma revisão na literatura objetivando identificar quais as principais técnicas estão sendo utilizadas no diagnóstico do glaucoma em imagens. Os trabalhos de Archarya et al.~\cite{acharya2011automated}, Simonthomas et al.~\cite{simonthomas2014automated}, Salam et al. \cite{salam2016automated} e Srinivasan et al.~\cite{srinivasancomplex} apresentaram soluções para a mesma problemática. A Acurácia obtida nos três trabalhos foi superior a 91\% com a utilização de descritores de textura. Sendo a \textit{Gray Level Co-occurrence Matrix} (GLCM), um ponto em comum em todos os trabalhos. No trabalho de Salam et al. \cite{salam2016automated}, os autores incluíram os descritores \textit{Color Moments} e \textit{Autocorrelogram} na etapa de extração de características, o que proporcionou 100\% de sensibilidade do método proposto. Entretanto, a utilização de bases de dados privadas dificulta a recriação de experimentos e consequentemente possíveis comparações. Entretanto os trabalhos de Kotyk et al. \cite{kotyk2016semi}, Claro et al. \cite{claro2016automatic} e Orlando et al. \cite{orlando2017convolutional}, os autores utilizaram bases públicas de fácil acesso. 

Em Kotyk et al. \cite{kotyk2016semi}, os autores propuseram um sistema semi-automatizado para detectar tanto o DO quanto a escavação. Essas duas regiões são utilizadas no cálculo do CDR. O canal vermelho do modelo de cor RGB é utilizado nas imagens da retina da base RIM-ONE-1. Na sequência, valores de limiar são utilizados para segmentação dessas regiões. As imagens são posteriormente processadas usando o descritor de textura de Haralick, e os valores obtidos são utilizados no classificador \textit{MultiLayer Perceptron} (MLP) para determinar a exatidão do sistema. A acurácia do sistema proposto foi da ordem de 86,43\%.


Claro et al. \cite{claro2016automatic} propuseram a detecção do glaucoma em imagens da retina. Os autores utilizaram informação de textura com o uso da GLCM juntamente com a entropia da imagem. Os modelos de cores utilizados foram o \textit{Red, Green, Blue} - (RGB), \textit{Hue, Saturation, Intensity} - (HSI) e \textit{Luminosity}, cromaticidade U e cromaticidade V - (LUV). A base de dados utilizada foi a RIM-ONE-1 e obtiveram uma acurácia da ordem de 93,03\% aplicando o classificador MLP.

Orlando et al. \cite{orlando2017convolutional} apresentaram resultados de uma análise da utilização das CNNs pré-treinadas, a partir de imagens da retina para detecção automatiza do glaucoma. Duas CNNs foram aplicadas nas imagens da base de dados DRISHTI para geração dos vetores de características, sendo elas a VGG-S e a Overfeat. São utilizadas técnicas de pré-processamento da imagem com o objetivo de melhorar a imagem para a etapa de extração de características, sendo estas técnicas a equalização de histograma, pintura dos vasos e um corte na imagem na região da cabeça do nervo óptico. A área sob a curva ROC (AUC) foi utilizada como métrica de avaliação tendo obtido resultado de 0,7626 no classificador \textit{Logistic Regression} (LR).

\section{Materiais e Métodos} 
\label{MM}

O objetivo deste trabalho é realizar o diagnóstico do glaucoma em imagens da retina. Para isso aplicou-se na região do disco óptico experimentos com os descritores de textura e forma, bem como \textit{Convolutional Neural Networks} (CNNs). Nós realizamos uma avaliação do potencial de descrição, em separado, de cada um destes descritores e concluímos que a união de diferentes características leva a melhores taxas de classificação.


\subsection{Método Proposto}
O método proposto segue o fluxograma da Figura \ref{fig:fluxo}. Esta metodologia parte de uma imagem segmentada do DO. Os descritores utilizados na etapa de extração de características foram a concatenação da GLCM com a penúltima camada totalmente conectada das CNN-\textit{AlexNet} \cite{Krizhevsky:2012}, CNN-\textit{CaffeNet} \cite{Jia:2014} e CNN-\textit{VGGFNet} \cite{Chatfield14}. Na etapa de seleção de atributos é utilizado o algoritmo de razão de ganho de informação, com o intuito de rankear as características mais significativas para as menos significativas. Por fim é aplicado o classificador \textit{Random Forest} para informar se a imagem é saudável ou glaucomatosa.

\begin{figure*}[!h]
	\centering
	\includegraphics[width=\textwidth]{Figs/SistemaProposto.png}
	\caption{Fluxograma da metodologia proposta para diagnóstico automático do glaucoma.}
	\label{fig:fluxo}
\end{figure*}



\subsection{Extração de Características}

A extração de características tem por finalidade descrever imagens em função de atributos extraídos. Segundo Salam et al. \cite{salam2016automated} a identificação de imagens glaucomatosas pode ser eficientemente realizada utilizando os descritores de textura e forma. Neste estudo forma avaliados os descritores de textura Local Binary Pattern (LBP) ~\cite{ojala1997unsupervised}; Gray Level Co-occurrence Matrix (GLCM) ~\cite{haralick1973textural}; Histogram of Oriented Gradients (HOG)~\cite{dalal2005histograms};  Tamura~\cite{tamura1978textural}; Gray Level Run Length Matrix (GLRLM) \cite{galloway1975texture}, ~\cite{chu1990use},~\cite{dasarathy1991image} e descritores de forma.  Adicionamos em nossa análise a descrição com CNNs através de três arquiteturas propostas recentemente: \textit{AlexNet} \cite{Krizhevsky:2012}, \textit{CaffeNet} \cite{Jia:2014} e \textit{VGGFNet} \cite{Chatfield14}. Estas arquiteturas são utilizadas em diversas aplicações, tais como a segmentação, descrição e classificação de imagens.

Todos os descritores de textura foram extraídos em cinco canais de cores diferentes, \textit{Red}, \textit{Green} e  \textit{Blue} do modelo RGB e os canais \textit{Hue} e \textit{Saturation} do modelo HSV. A banda \textit{V} do modelo HSV não é utilizada, visto que, nas imagens retinianas esta banda de cor é quase a mesma que o canal de cor vermelho. Já para as CNNs, utilizamos como entrada a imagem original no sistema de cor RGB sem redimensionamento. A Tabela \ref{tab:extracao} apresenta um resumo dos descritores.



\begin{table*}[!ht]
	\tiny
	\centering
	\caption{Informação dos descritores utilizado neste trabalho.}
	\label{tab:extracao}
	\resizebox{1 \textwidth}{!}{%
		\begin{tabular}{|c|c|c|cclll|}
			\hline
			\textbf{Descritores}  & \textbf{Características}&\textbf{Qt de Atributos} 
			\\ \hline
			
			LBP \cite{ojala1997unsupervised} & Histograma de textura & 1280\\ \hline 
			GLCM \cite{haralick1973textural} & Contraste, correlação, energia, homogeneidade (0º, 45º, 90º e 135º) e entropia & 85\\ 
			HOG ~\cite{dalal2005histograms} & Histograma de Gradientes Orientados&  405 \\ \hline
			Tamura \cite{tamura1978textural} & Contraste, Direcionalidade e \textit{Coarseness}& 15
			\\ \hline
			GLRLM \cite{galloway1975texture},~\cite{chu1990use} e \cite{dasarathy1991image} & \begin{tabular}[c]{@{}c@{}}  \textit{Short-Run Emphasis}, \textit{Long-Run Emphasis},\\  \textit{Gray Level distribuition}, \textit{Run Lenght distribuition}, \\ \textit{Run Percentage}, \textit{Low Gray Level Run Emphasis} \\ textit{High Gray Level Run Emphasis}, \textit{Short Run Low Gray Level Emphasis}, \\ \textit{Short Run High Gray Level Emphasis}, \textit{Long Run Low Gray Level Emphasis} \\ e \textit{Long Run High Gray Level Emphasis} (0º, 45º, 90º e 135º)\end{tabular} & 220   \\ \hline
			
			Morfologia & Area, Diâmetro, Perímetro, Circularidade e Extensão & 5 \\ \hline
			CNNs \cite{Krizhevsky:2012}, \cite{Jia:2014} e \cite{Chatfield14} & Redes Neurais Convolucionais & 4096\\
			
			\hline
		\end{tabular} 
	}
\end{table*}

As CNNs utilizadas neste trabalho são pré-treinadas na base natural de imagens ImageNet e estão disponíveis no \textit{website} MatConvNet\footnote{http://www.vlfeat.org/matconvnet/}. Devido a pequena quantidade de imagens obtidas neste trabalho, nós utilizamos a técnica de transferência de aprendizado, que consiste na extração da penúltima camada totalmente conectada da rede como vetor de características. A utilização de CNNs pré-treinadas na ImageNet proporciona a extração de características gerais da imagem, sendo elas: borda, cor, textura e contorno. Com o grande nível de abstração dos dados nas últimas camadas da CNN, não é possível identificar cada uma das características e sua origem a partir da imagem. Portanto, utilizamos a seleção dos atributos que possuem uma maior ganho para assim treinar e validar com um classificador.


\subsection{Seleção de Atributos e Classificação}
Após a criação do vetor de características, obtidos na etapa anterior, realizou-se uma seleção de atributos. Esta seleção tem como objetivo eliminar atributos desnecessários e, consequentemente, simplificar o modelo de predição, melhorar a performance dos algoritmos, reduzir o custo computacional destes modelos, além de fornecer um melhor entendimento sobre os resultados encontrados.

O algoritmo utilizado para seleção de atributos foi a razão de ganho, que é uma métrica de ganho de informação. Este algoritmo é um tipo de filtro, que tende a superestimar a qualidade dos atributos com muitos valores \cite{quinlan1986induction}. Neste contexto, realizou-se 10 testes, variando o tamanho do vetor de características em 5\% 10\%, 20\%, 30\%, 40\%, 50\%, 60\%, 70\%, 80\% e 90\%, para que possamos excluir os atributos menos significativos. 

O software utilizado para classificação foi o \textit{Waikato Environment for Knowledge Analysis} (WEKA), sendo que esta ferramenta oferece um conjunto de algoritmos de aprendizado de máquina para mineração de dados, nele são disponibilizados algoritmos de classificação, regressão, agrupamento, seleção de características e regras de associação \cite{hall2009weka}. Os algoritmos utilizados nos experimentos desse trabalho foram o \textit{Support Vector Machine} (SVM) \cite{cortes1995support}, \textit{MultiLayer Perceptron} (MLP)  \cite{rumelhart1985learning} e \textit{Random Forest} (RF) \cite{breiman2001random}.


Foram realizados vários testes para identificar a melhor configuração de cada um dos classificadores avaliados. O SVM foi executado utilizando uma função de \textit{kernel} linear. O classificador MLP, foi utilizado com uma camada oculta com 2 neurônios. O classificador \textit{Random Forest} foi utilizado com uma profundidade máxima das árvores ilimitada e o número de árvores foi 100.



\subsection{Métricas de Avaliação}
\label{MA}

Para a análise dos resultados de uma classificação, foram calculados os valores da matriz de confusão, sendo: Verdadeiro Positivo (VP), número de imagens corretamente classificadas como glaucomatosas; Falso Negativo (FN) é o número de imagens glaucomatosas classificadas incorretamente como saudáveis; Falso Positivo (FP) é o número de imagens saudáveis classificadas incorretamente como glaucomatosas; e Verdadeiro Negativo (VN), número de imagens corretamente classificadas como saudáveis \cite{chimieski2013association}. A partir desses valores, são calculadas as métricas de desempenho da metodologia apresentada neste estudo, sendo elas as taxas de Precisão (P), Área Sob a Curva ROC (AUC) e Acurácia (A) \cite{powers2007evaluation}.

Outra medida utilizada foi o índice Kappa (K), que vem sendo recomendado como uma medida apropriada da exatidão por representar inteiramente a matriz de confusão. Ele toma todos os elementos da matriz em consideração, ao invés de apenas aqueles que se situam na diagonal principal, o que ocorre quando se calcula a exatidão global da classificação \cite{rosenfield1986coefficient}. De acordo com Landis e Koch \cite{landis1977measurement} o valor de K assume valores entre 0 e 1. O resultado é qualificado de acordo com o valor de K da seguinte forma: K $\leq 0,2 $: Ruim; $0,2$ $<$ K $\leq 0,4 $: Razoável; $0,4$ $<$ K $\leq 0,6 $: Bom; $0,6$ $<$ K $\leq 0,8 $: Muito Bom; K $>$ $0,8$: Excelente. 

\subsection{Base de Imagens}

Um dos desafios no processamento de imagens de glaucoma é a habilidade de diagnosticar a doença em bases de dados com características distintas. Assim, avaliamos a robustez da metodologia proposta em quatro bases de dados diferentes: DRISHTI \cite{sivaswamy2014drishti} e RIM-ONE \cite{Fumero:2011} em suas 3 versões. Ao todo, nosso proposta foi avaliada em 873 imagens, sendo 489 saudáveis e 384 glaucomatosas.


A base DRISHTI é composta por 101 imagens de retina  coletadas no \textit{Aravind Eye Hospital}, Madurai, na India. Todas as imagens foram tiradas com centro no DO, com um ``campo de visão'' de 30º e dimensões 2896$\times$1944 pixels em formato PNG. 


As imagens das bases RIM-ONE 1, 2 e 3 foram registradas em três diferentes regiões da Espanha. A RIM-ONE-1 é composta de 158 imagens de retina. O conjunto está dividido em 118 saudáveis, 12 com glaucoma inicial, 14 com glaucoma moderado e 14 com glaucoma profundo. As imagens foram capturadas por uma câmera Nidek AFC-210 com um corpo de uma Canon EOS 5D Mark II de 21,1 megapixels. A base foi criada com a colaboração de quatro oftalmologistas e um optometrista.

A RIM-ONE-2 possui um conjunto de 455 imagens da retina, sendo 255 imagens saudáveis e 200 glaucomatosas. Todas as imagens possuem o padrão ouro da segmentação da região do disco óptico. As imagens variam de 345$\times$386 à 828$\times$818 pixels.


A RIM-ONE-3 é um conjunto de dados que consiste em 159 imagens de retina, sendo que, 85 imagens saudáveis e 74 glaucomatosas. Todas as imagens foram tiradas por uma câmera de fundo não estéreo Kowa WX 3D. A imagens são centrados no DO com um ``campo de visão'' de 34º e as imagens estereoscópicas são capturadas no mesmo tiro da câmera, dando uma resolução de 2144$\times$1424 pixels. O diagnóstifo foi realizado por dois especialistas.

A Figura \ref{fig:Bases} apresenta exemplos de imagens disponíveis nas bases de dados utilizadas neste trabalho. A Figura \ref{fig:Bases}(a) mostra um exemplo de imagem da base DRISHTI, com a sua respectiva marcação do DO demonstrada na Figura \ref{fig:Bases}(b), ou comumente chamada de padrão ouro. A Figura Figura \ref{fig:Bases}(c) apresenta um exemplo de imagem da base RIM-ONE-1, e seu padrão ouro é demonstrado na \ref{fig:Bases}(d). 


\begin{figure*}[h!]
	\centering
	\subfigure[]{
		\label{fig:Normal}
		\includegraphics[width=.23\linewidth]{Figs/drishtiGS_035}}
	\subfigure[]{
		\label{fig:Glaucoma}
		\includegraphics[width=.23\linewidth]{Figs/drishtiGS_035_ODsegSoftmap}}
	\subfigure[]{
		\label{fig:Glaucoma}
		\includegraphics[width=.23\linewidth]{Figs/Im069_1}}
	\subfigure[]{
		\label{fig:Glaucoma}
		\includegraphics[width=.23\linewidth]{Figs/Im069-exp1}}
	\caption{Exemplos de imagens das bases de dados: (a) DRISHTI, (b) Padrão Ouro DRISHTI, (c) RIM-ONE-1 e (d) Padrão ouro RIM-ONE-1.}
	\label{fig:Bases}
\end{figure*}


\section{Resultados}
\label{RD}

O Software utilizado para classificação foi o WEKA \cite{hall2009weka} e, o método de validação utilizado foi o \textit{k-fold cross-validation} (com \textit{k} = 10). A Tabela \ref{tab:Estrategia1} demonstra os resultados obtidos, onde em cada descritor foi aplicado nas 873 imagens do fundo de olho disponíveis nas quatro bases de dados utilizadas. Na última linha desta tabela encontra-se o resultado da concatenação de todos os descritores testados (Híbrido).

\begin{table*}[ht]
	\centering
	\caption{Resultados obtidos com todos os atributos.}
	\label{tab:Estrategia1}
	\resizebox{1\textwidth}{!}{%
		\begin{tabular}{|l|cccc|cccc|cccc|}
			\hline
			& \multicolumn{4}{c|}{SVM} & \multicolumn{4}{c|}{MLP} & \multicolumn{4}{c|}{Random Forest} \\ \hline
			\multicolumn{1}{|c|}{Descritor} & P(\%) & AUC & A(\%) & K & P(\%) & AUC & A(\%) &  K & P(\%) & AUC & A(\%) & K \\ \hline
			LBP & 34,10 & 0,5 & 58,41 &  0 & 69,00 & 0,8087 & 68,61 &  0,36 & 
			71,50 & 0,8255 & 71,70 &  0,41 \\
			
			GLCM &  81,20 & 0,8088 & 80,52 & 0,58 & 82,90 & 0,929 & 82,93 & 0,64 & 83,30 & 0,9353 & 83,27 & 0,65 \\
			
			HOG & 67,00 & 0,7774 & 67,46 &  0,30 & 71,00 & 0,8107 & 71,02 & 0,40 & 69,40 & 0,8464 & 69,53 & 0,34 \\
			
			Tamura & 63,17&0,6851 &64,14 & 0,21 & 71,40 & 0,7887 & 71,59 &  0,41 & 69,40 & 0,7907& 69,76 &  0,36\\
			
			GLRLM & 64,80&0,8034 & 65,06 & 0,27 & 65,30 & 0,6272 & 65,75 & 0,26 & 74,70 & 0,8392 & 74,80 & 0,47 \\
			
			Morfologia & 53,80 & 0,5298&  52,11 &  0,05 & 62,60 & 0,6974 & 63,00 & 0,22 & 66,20 & 0,7219 & 66,32 &  0,31\\
			
			CNN-\textit{AlexNet} & \textbf{82,50} & \textbf{0,8204} & \textbf{82,47} &  \textbf{0,64} & 80,60 &  0,8798 & 80,52 &  0,60 & 80,30 & 0,8934 & 80,29 &  0,59  \\
			
			CNN-\textit{CaffeNet} & 80,80 & 0,8024 & 80,87 & 0,60 & 80,70 & 0,8868 & 80,75 & 0,60 & 81,60 & 0,9016 & 81,55 &  0,62\\
			
			CNN-\textit{VGGFNet} & 80,70 & 0,8022 & 80,50 & 0,60 & 79,90 & 0,881 & 79,95 &  0,59 & 82,20 & 0,8943 & 82,12 & 0,63\\
			
			Híbrido & 67,70 & 0,7923 & 66,20 &  0,33& \textbf{83,10} & \textbf{0,9334}& \textbf{83,16}& \textbf{0,65} & \textbf{85,60} & \textbf{0,9382} & \textbf{85,56} &  \textbf{0,70}\\
			\hline
		\end{tabular}%
	}
\end{table*}



A partir da análise da Tabela \ref{tab:Estrategia1}, podemos perceber que, em todos os três classificadores testados, GLCM e as CNNs obtiveram uma taxa de acerto maior em relação aos outros descritores. A GLCM obteve, no classificador MLP e \textit{Random Forest}, o melhor resultado individual entres os descritores, com 82,93\% e 83,27\% de acurácia, respectivamente. No classificador SVM o melhor resultado encontrado foi com a CNN-\textit{AlexNet} que obteve 82,47\% de acurácia. 

Pode-se observar também que com a concatenação de todos
os descritores formou-se um descritor híbrido, onde foi possível obter uma melhoria em todas as métricas de avaliação (precisão, \textit{recall}, acurácia, \textit{F-measure} e Kappa) nos classificadores MLP e \textit{Random Forest}, com acurácia de 83,16\% e
85,56\%, respectivamente. O Kappa obtido demonstra
que os resultados são considerados “Muito Bons” e que de acordo com o AUC alcançado, seu resultado é considerado satisfatório, pois possui um valor acima de 0,7.

Assim como no trabalho de Acharya et al., 2011 \cite{acharya2011automated}, este estudo teve o \textit{Random Forest} e o MLP como os classificadores que apresentaram os melhores resultados na maioria dos descritores. Assim, com base nestes experimentos, podemos concluir que uma análise individual de todos estes descritores, a GLCM e as arquiteturas de CNNs obtiveram os melhores resultados. Com isso, investigamos o uso de um novo descritor composto por a concatenação estes quatro descritores: GLCM, CNN-\textit{AlexNet}, CNN-\textit{CaffeNet} e CNN-\textit{VGGFNet}.

Com base nesta análise realizou-se 10 testes, onde a seleção de atributos é utilizada com o tamanho do vetor de características variando em 5\%, 10\%, 20\%, 30\%, 40\%, 50\%, 60\%, 70\%,
80\% e 90\%, para que possamos excluir os atributos menos significativos e tentar melhorar os resultados. 
Ao total foram feitos 30 testes (10 testes de porcentagens de seleção de atributos $\times$ 3 descritores) utilizando o classificador \textit{Random Forest}, e seus resultados podem ser visualizados na Figura \ref{fig:grafico_t}. Nesta figura também é demonstrado a quantidade de atributos pertencentes a cada descritor composto no descritor GLCM+CNNs (Figura \ref{fig:tabela_g}), e podemos inferir que o descritor GLCM, que possui 85 atributos extraídos, obteve uma taxa significativa nos atributos mais importantes.

\begin{figure*}[h!]
	\centering
	
	\subfigure[]{
		\label{fig:grafico_t}
		\includegraphics[width=\columnwidth]{Figs/20180110053229.png}}
	\subfigure[]{
		\label{fig:tabela_g}
		\includegraphics[width=\columnwidth]{Figs/Tabela_selecao}}
	\caption{Comparação dos resultados dos descritores GLCM, CNNs e GLCM+CNNs com a seleção de porcentagem dos atributos: (a) Representação dos resultados obtidos e (b) Composição do descritor GLCM+CNNs}.
	\label{fig:grafico}
\end{figure*}


A Tabela \ref{tab:selecao} demonstra a porcentagem que apresentou o melhor resultado nos descritores GLCM, nas CNNs (CNN-\textit{AlexNet}, CNN-\textit{CaffeNet} e CNN-\textit{VGGFNet}) e com a junção da GLCM com as CNNs. Podemos visualizar que no descritor GLCM, a melhor quantidade de atributos foi de 90\%, o que corresponde a 77 atributos, onde se obteve uma acurácia de 84,19\%. As CNNs obtiveram um melhor resultado com apenas 5\%, ou seja, 614 atributos de 12.288 foram os atributos mais significativos, de acordo com o algoritmo de seleção de atributos razão de ganho, tendo obtido 82,70\% de acurácia. Os descritores GLCM e CNNs conseguiram individualmente resultados considerados ``Muito Bons'' de acordo com a Seção \ref{MA}, que demonstra o nível de exatidão da classificação a partir do índice Kappa (K). Contudo, com a concatenação destes, o resultado melhorou significativamente, alcançando uma acurácia na ordem de 91,06\% com apenas 5\% dos melhores atributos, o que equivale a 619 atributos de 12.373. Como o índice Kappa (K) foi de 0,81, este resultado é considerado ``Excelente'' e demonstra a eficiência  da união de características de textura com CNNs pré-treinadas na classificação de imagens glaucomatosas.


\begin{table*}[!ht] \footnotesize
	\centering
	
	\caption{Melhores resultados obtidos com a seleção de atributos.}
	\label{tab:selecao}
	
	\resizebox{0.8\textwidth}{!}{%
		\begin{tabular} {|c|cccccc|}
			\hline
			
			
			Descritor & \multirow{6}{*}{} (\%) dos Dados & Qt de Atributos& P(\%) & AUC & A(\%)  & K   
			\\  \hline
			
			GLCM & \multirow{5}{*}{} 90 & 77 &84,20 & 0,9492 & 84,19 & 0,67 \\ 
			CNNs & \multirow{5}{*}{} 5 & 614 & 82,80 & 0,9007 & 82,70 & 0,62 \\
			GLCM+CNNs & \multirow{5}{*}{} 5 & 619& \textbf{91,20} & \textbf{0,9633} & \textbf{91,06} &\textbf{0,81}\\
			
			\hline
		\end{tabular}%
	}
\end{table*}




\section{Discussão}
\label{DIS}


Com a finalidade de validar o método proposto, foram realizadas comparações com métodos do estado da arte. A Tabela \ref{tab:Discus1} apresenta uma comparação entre o método proposto e as técnicas de Kotyk et al. \cite{kotyk2016semi} e Claro et al. \cite{claro2016automatic}. Nessa comparação os algoritmos originais foram executados nas 873 imagens disponíveis. Nossa proposta obteve um melhor desempenho quando comparado aos demais. A acurácia obtida foi de 91,06\% e Kappa de 0,81 o que é um resultado considerado ``Excelente'', já os outros dois trabalhos alcançaram índice Kappa considerado ``Muito Bom''.

\begin{table*}[!ht] \tiny
	\centering
	
	\caption{Comparação do método proposto com os trabalhos relacionados.}
	\label{tab:Discus1}
	
	\resizebox{0.65 \textwidth}{!}{%
		\begin{tabular}{|ccccc|}
			\hline
			
			\textbf{Trabalhos}  &  \textbf{P(\%)}& \textbf{ AUC}  & \textbf{A(\%)} & K
			\\ \hline
			Kotyk et al. \cite{kotyk2016semi}   & 86,50&0,952 & 86,48 & 0,72\\ 
			
			Claro et al. \cite{claro2016automatic} & 87,00 & 0,955 &87,05& 0,73 \\ 
			\textbf{Método Proposto}  &\textbf{91,20}&\textbf{0,963} & \textbf{91,06} & \textbf{0,81} 
			
			\\
			
			\hline
		\end{tabular} 
	}
\end{table*}


A Tabela \ref{tab:Discus2} apresenta a comparação do método desenvolvido neste estudo com o do trabalho de Orlando et al. \cite{orlando2017convolutional}. Este trabalho também utiliza redes neurais convolucionais como descritor. Contudo, essas redes foram diferentes das aplicadas nesse estudo. Como não tivemos acesso ao código original dos autores optamos por executar nosso método na base DRISHTI \cite{sivaswamy2014drishti} (a mesma utilizada em \cite{orlando2017convolutional}). A única métrica de avaliação apresentada pelos autores é a AUC com valor 0,762. Nossa proposta obteve melhor desempenho na base DRSHTI com uma AUC de 0,814.


\begin{table*}[!ht] 
	\centering
	
	\caption{Comparação do método proposto com os trabalhos relacionados.}
	\label{tab:Discus2}
	
	\resizebox{\columnwidth}{!}{%
		\begin{tabular}{|ccccc|}
			\hline
			
			\textbf{Trabalhos}  &  \textbf{P(\%)}& \textbf{ AUC}  & \textbf{A(\%)} & K
			\\\hline
			Orlando et al. \cite{orlando2017convolutional}   & -&0,762 & - & -\\ 
			\textbf{Método Proposto}  &\textbf{80,60}&\textbf{0,814} & \textbf{80,19} & \textbf{0,46}
			
			\\
			
			\hline
		\end{tabular} 
	}
\end{table*}

Os resultados apresentados nas Tabelas \ref{tab:Discus1} e \ref{tab:Discus2} evidenciam a validade da nossa proposta. Dado que nosso método se baseia na união de descritores de textura e transferência de aprendizado em CNNs conseguimos demonstrar que ele é mais eficiente que métodos baseados apenas em textura \cite{kotyk2016semi} e \cite{claro2016automatic} e apenas em transferência de aprendizado \cite{orlando2017convolutional}. 


\section{Conclusão}
\label{CO}
Muitos trabalhos identificados na literatura, demonstram que as pesquisas têm se direcionado para a área de processamento digital de imagens, na qual o diagnóstico automático do glaucoma é uma destas subáreas. Neste estudo, foi exposto uma estratégia para o diagnóstico automático do glaucoma, que utiliza descritores de textura, forma e redes neurais convolucionais nas imagens digitais de fundo de olho, para que estas sejam classificadas como glaucomatosas ou não.

De acordo com os achados na literatura, percebeu-se que os autores costumam utilizar suas próprias bases de dados ou apenas uma base de dados. Ao se utilizar 4 bases distintas nota-se que cada uma delas apresentam características específicas. A extração de características e a classificação são considerados as etapas mais importantes no diagnóstico automático de diferentes sistemas computacionais. Em razão disto foram utilizados os descritores de textura, forma e redes neurais convolucionais, além de um algoritmo de seleção de atributos para auxílio no desempenho do método. Com a concatenação das CNNs com a GLCM obteve-se um desempenho considerado ``Excelente'' pelo índice kappa, tendo uma acurácia de 91,06\%. 

Os resultados apresentados são promissores. Entretanto, podem ser melhorados. Como trabalhos futuros, propõe-se a extração de características na região da escavação (\textit{cup}), além da região do disco óptico, pois, com estas duas regiões pode-se realizar cálculos que auxiliam no diagnóstico do glaucoma, como o cálculo da razão entre o raio da escavação e o raio do disco óptico \textit{Cup to Disc Ratio} (CDR).

\section*{Agradecimentos}
Os autores agradecem a Fundação de Apoio à Pesquisa do Estado do Piauí (FAPEPI) por patrocinar nossa pesquisa.

\section*{Contribuição dos Autores}
A autora Maíla Claro é mestranda (conclusão em março) e principal responsável pela execução do trabalho e escrita do artigo. Os professores Rodrigo Veras e André Santana são, respectivamente, orientador e co-orientador da autora principal. Eles orientaram ela e os demais alunos na execução dos testes, escrita e contribuíram com sua experiência na versão final do artigo. Os autores Luis Vogado e Leonardo Sousa auxiliaram a autora principal na execução de testes, escrita inicial do artigo e revisão da versão final.

%----------------------------------------------------------------------------------------
%	REFERENCE LIST
%----------------------------------------------------------------------------------------

\phantomsection
\balance

\makeatletter
\renewcommand\@biblabel[1]{{\parbox{0.7cm}{[#1]}}}
\makeatother
% References
\renewcommand{\refname}{Referências}
\bibliography{Bibliografia}


\balance
\end{document}